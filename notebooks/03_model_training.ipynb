{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "id": "8Wbwl3O3Kh-X",
    "outputId": "f56bcd31-a5ef-41dc-c1f9-a11e251e7fb7"
   },
   "outputs": [],
   "source": [
    "# Cell 1: Mount Drive and Load Data\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!pip install xgboost optuna -q\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load dataset from Google Drive\n",
    "dataset = pd.read_csv('/content/drive/MyDrive/stock_prediction_data/processed_dataset.csv')\n",
    "\n",
    "# Sort by date for temporal splitting\n",
    "dataset['date'] = pd.to_datetime(dataset['date'])\n",
    "dataset = dataset.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "# Use raw returns as target (better direction accuracy than excess returns)\n",
    "target_col = 'target_return'\n",
    "\n",
    "print(f\"Loaded dataset: {dataset.shape}\")\n",
    "print(f\"Samples: {len(dataset)}, Companies: {dataset['ticker'].nunique()}\")\n",
    "print(f\"Date range: {dataset['date'].min().date()} to {dataset['date'].max().date()}\")\n",
    "print(f\"Target: {target_col}\")\n",
    "print(f\"  Mean: {dataset[target_col].mean():.4f}, Std: {dataset[target_col].std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "2WjWDj48K733",
    "outputId": "3a783ef0-4e5f-4c79-df91-6278f265b399"
   },
   "outputs": [],
   "source": "# Cell 2: Feature Selection\nmeta_cols = ['ticker', 'date', 'target_return', 'target_excess_return', 'benchmark_return']\nall_feature_cols = [c for c in dataset.columns if c not in meta_cols]\n\nprint(f\"Starting features: {len(all_feature_cols)}\")\n\nX_raw = dataset[all_feature_cols].copy()\ny = dataset[target_col].copy()\n\n# 1. Drop features with zero variance\nvariances = X_raw.var()\nzero_var = variances[variances == 0].index.tolist()\nif zero_var:\n    print(f\"Dropping {len(zero_var)} zero-variance features: {zero_var}\")\n    X_raw = X_raw.drop(columns=zero_var)\n\n# 2. Drop highly correlated features (>0.95)\ncorr_matrix = X_raw.corr().abs()\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\nhigh_corr_pairs = []\nto_drop = set()\nfor col in upper.columns:\n    correlated = upper.index[upper[col] > 0.95].tolist()\n    for c in correlated:\n        if c not in to_drop:\n            high_corr_pairs.append((col, c, corr_matrix.loc[col, c]))\n            to_drop.add(c)\n\nif to_drop:\n    print(f\"\\nDropping {len(to_drop)} highly correlated features (r > 0.95):\")\n    for col, c, r in high_corr_pairs:\n        print(f\"  {c} (corr={r:.3f} with {col})\")\n    X_raw = X_raw.drop(columns=list(to_drop))\n\n# 3. Drop features with very low correlation to target (noise removal)\n# With 436 companies, many features are pure noise that the model overfits to\ntarget_corr = X_raw.corrwith(y).abs().sort_values(ascending=False)\nprint(f\"\\nFeature-target correlations:\")\nfor feat, corr in target_corr.items():\n    marker = \"  \" if corr >= 0.02 else \"X \"\n    print(f\"  {marker}{feat:<35s} |r|={corr:.4f}\")\n\nlow_corr = target_corr[target_corr < 0.02].index.tolist()\nif low_corr:\n    print(f\"\\nDropping {len(low_corr)} low-correlation features (|r| < 0.02): {low_corr}\")\n    X_raw = X_raw.drop(columns=low_corr)\n\nfeature_columns = list(X_raw.columns)\nprint(f\"\\nSelected features: {len(feature_columns)}\")\nprint(f\"Features: {feature_columns}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bj94aD0AK93A",
    "outputId": "d2de7cc8-afa3-41d6-b525-f771f1a48c1a"
   },
   "outputs": [],
   "source": [
    "# Cell 3: Temporal Train/Test Split + Time-Series CV\n",
    "\n",
    "X = dataset[feature_columns].copy()\n",
    "y = dataset[target_col].copy()\n",
    "\n",
    "# Temporal split: train on earlier data, test on most recent 20%\n",
    "unique_dates = sorted(dataset['date'].unique())\n",
    "n_dates = len(unique_dates)\n",
    "cutoff_idx = int(n_dates * 0.8)\n",
    "cutoff_date = unique_dates[cutoff_idx]\n",
    "\n",
    "train_mask = dataset['date'] < cutoff_date\n",
    "test_mask = dataset['date'] >= cutoff_date\n",
    "\n",
    "X_train_raw = X[train_mask]\n",
    "X_test_raw = X[test_mask]\n",
    "y_train = y[train_mask].values\n",
    "y_test = y[test_mask].values\n",
    "\n",
    "print(f\"=== Temporal Split ===\")\n",
    "print(f\"Cutoff date: {pd.Timestamp(cutoff_date).date()}\")\n",
    "print(f\"Training: {len(X_train_raw)} samples ({dataset[train_mask]['date'].min().date()} to {dataset[train_mask]['date'].max().date()})\")\n",
    "print(f\"Test:     {len(X_test_raw)} samples ({dataset[test_mask]['date'].min().date()} to {dataset[test_mask]['date'].max().date()})\")\n",
    "\n",
    "# RobustScaler: uses median/IQR, resistant to outliers (PE ratio max 17,474 etc)\n",
    "scaler = RobustScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train_raw), columns=feature_columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test_raw), columns=feature_columns)\n",
    "\n",
    "# Build expanding-window CV splits for training data\n",
    "train_dates = sorted(dataset[train_mask]['date'].unique())\n",
    "n_train_dates = len(train_dates)\n",
    "n_folds = 5\n",
    "fold_size = n_train_dates // (n_folds + 1)\n",
    "\n",
    "cv_splits = []\n",
    "for i in range(n_folds):\n",
    "    train_end = (i + 2) * fold_size\n",
    "    val_start = train_end\n",
    "    val_end = min(train_end + fold_size, n_train_dates)\n",
    "\n",
    "    cv_train_dates = set(train_dates[:train_end])\n",
    "    cv_val_dates = set(train_dates[val_start:val_end])\n",
    "\n",
    "    train_idx = [j for j, d in enumerate(dataset[train_mask]['date']) if d in cv_train_dates]\n",
    "    val_idx = [j for j, d in enumerate(dataset[train_mask]['date']) if d in cv_val_dates]\n",
    "\n",
    "    if len(val_idx) > 0:\n",
    "        cv_splits.append((train_idx, val_idx))\n",
    "\n",
    "print(f\"\\n=== Time-Series CV ({len(cv_splits)} folds) ===\")\n",
    "for i, (tr, va) in enumerate(cv_splits):\n",
    "    print(f\"  Fold {i+1}: train={len(tr)} samples, val={len(va)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u8jDIFp2LAK5",
    "outputId": "bb41aabf-0a76-40e8-fe64-e3e6e2c6a884"
   },
   "outputs": [],
   "source": "# Cell 4: Hyperparameter Tuning with Optuna (Bayesian Optimization)\n# Constrained search space to prevent overfitting with 436 companies\n\ndef objective(trial):\n    params = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n        'max_depth': trial.suggest_int('max_depth', 2, 4),\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n        'subsample': trial.suggest_float('subsample', 0.5, 0.8),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 0.8),\n        'min_child_weight': trial.suggest_int('min_child_weight', 10, 50),\n        'reg_alpha': trial.suggest_float('reg_alpha', 0.1, 50.0, log=True),\n        'reg_lambda': trial.suggest_float('reg_lambda', 1.0, 50.0, log=True),\n        'huber_slope': trial.suggest_float('huber_slope', 0.05, 0.3),\n    }\n\n    cv_scores = []\n    for train_idx, val_idx in cv_splits:\n        model = xgb.XGBRegressor(\n            **{k: v for k, v in params.items() if k != 'huber_slope'},\n            huber_slope=params['huber_slope'],\n            random_state=42,\n            objective='reg:pseudohubererror',\n            verbosity=0,\n        )\n        model.fit(X_train.values[train_idx], y_train[train_idx])\n        preds = model.predict(X_train.values[val_idx])\n        rmse = np.sqrt(mean_squared_error(y_train[val_idx], preds))\n        cv_scores.append(rmse)\n\n    return np.mean(cv_scores)\n\nprint(\"Running Optuna hyperparameter search (50 trials, constrained for regularization)...\")\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=50, show_progress_bar=True)\n\nbest_params = study.best_params\nprint(f\"\\n=== Best Parameters ===\")\nfor k, v in best_params.items():\n    if isinstance(v, float):\n        print(f\"  {k}: {v:.4f}\")\n    else:\n        print(f\"  {k}: {v}\")\n\n# Re-run best params through CV folds to get per-fold scores for std\nbest_cv_scores = []\nfor train_idx, val_idx in cv_splits:\n    bp = best_params.copy()\n    hs = bp.pop('huber_slope')\n    fold_model = xgb.XGBRegressor(\n        **bp,\n        huber_slope=hs,\n        random_state=42,\n        objective='reg:pseudohubererror',\n        verbosity=0,\n    )\n    fold_model.fit(X_train.values[train_idx], y_train[train_idx])\n    fold_preds = fold_model.predict(X_train.values[val_idx])\n    fold_rmse = np.sqrt(mean_squared_error(y_train[val_idx], fold_preds))\n    best_cv_scores.append(fold_rmse)\n\ncv_rmse_mean = np.mean(best_cv_scores)\ncv_rmse_std = np.std(best_cv_scores)\nprint(f\"\\nCV RMSE with best params: {cv_rmse_mean:.4f} +/- {cv_rmse_std:.4f}\")\nprint(f\"Per-fold: {[f'{s:.4f}' for s in best_cv_scores]}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HbUU3TeKLBsS",
    "outputId": "10db56e4-5b2c-4863-9c61-e632beedd103"
   },
   "outputs": [],
   "source": "# Cell 5: Train Final Model, Direction Classifier, and Calibration\n\n# --- Regression model with Huber loss ---\nhuber_slope = best_params.pop('huber_slope')\nmodel = xgb.XGBRegressor(\n    **best_params,\n    huber_slope=huber_slope,\n    random_state=42,\n    objective='reg:pseudohubererror',\n    verbosity=0,\n)\nmodel.fit(X_train.values, y_train)\n\ny_pred_train = model.predict(X_train.values)\ny_pred_test = model.predict(X_test.values)\n\n# --- Direction classifier (simple, independent tuning) ---\ny_train_dir = (y_train > 0).astype(int)\ny_test_dir = (y_test > 0).astype(int)\n\n# Simple classifier: shallow trees, heavy regularization\ndir_model = xgb.XGBClassifier(\n    n_estimators=100,\n    max_depth=2,\n    learning_rate=0.05,\n    subsample=0.7,\n    colsample_bytree=0.6,\n    min_child_weight=20,\n    reg_alpha=1.0,\n    reg_lambda=5.0,\n    random_state=42,\n    objective='binary:logistic',\n    eval_metric='logloss',\n    verbosity=0,\n)\ndir_model.fit(X_train.values, y_train_dir)\ndir_probs = dir_model.predict_proba(X_test.values)[:, 1]  # P(up)\ndir_preds = (dir_probs > 0.5).astype(int)\n\ndir_correct = np.sum(dir_preds == y_test_dir)\ndir_accuracy = dir_correct / len(y_test)\n\n# --- Prediction calibration ---\n# Scale regression predictions to match training data variance\npred_std = y_pred_test.std()\nactual_std = y_train.std()\npred_mean = y_pred_test.mean()\ntrain_mean = y_train.mean()\n\nif pred_std > 0:\n    y_pred_calibrated = (y_pred_test - pred_mean) * (actual_std / pred_std) + train_mean\nelse:\n    y_pred_calibrated = y_pred_test.copy()\n\n# --- Ensemble: blend regression direction with classifier confidence ---\ndir_signal = 2 * dir_probs - 1  # maps [0,1] -> [-1,1]\ny_pred_ensemble = y_pred_calibrated.copy()\n# Flip calibrated prediction sign when classifier strongly disagrees\nfor i in range(len(y_pred_ensemble)):\n    if np.sign(y_pred_calibrated[i]) != np.sign(dir_signal[i]):\n        # Use classifier's direction with calibrated magnitude\n        y_pred_ensemble[i] = abs(y_pred_calibrated[i]) * np.sign(dir_signal[i])\n\n# Restore huber_slope in best_params for saving\nbest_params['huber_slope'] = huber_slope\n\n# --- Evaluate all variants ---\nprint(\"=\" * 65)\nprint(\"    PREDICTION METHOD COMPARISON\")\nprint(\"=\" * 65)\nprint(f\"{'Method':<25s} {'RMSE':>8s} {'R2':>8s} {'Dir Acc':>8s} {'Train R2':>8s}\")\nprint(\"-\" * 60)\n\n# Check overfitting\ntrain_rmse_check = np.sqrt(mean_squared_error(y_train, y_pred_train))\ntrain_r2_check = r2_score(y_train, y_pred_train)\n\nvariants = {\n    'Raw Regression': y_pred_test,\n    'Calibrated Regression': y_pred_calibrated,\n    'Ensemble': y_pred_ensemble,\n}\nfor name, preds in variants.items():\n    rmse = np.sqrt(mean_squared_error(y_test, preds))\n    r2 = r2_score(y_test, preds)\n    da = np.mean(np.sign(y_test) == np.sign(preds))\n    tr2 = f\"{train_r2_check:.4f}\" if name == 'Raw Regression' else \"\"\n    print(f\"  {name:<23s} {rmse:>8.4f} {r2:>8.4f} {da:>7.1%} {tr2:>8s}\")\n\nprint(f\"  {'Direction Classifier':<23s} {'':>8s} {'':>8s} {dir_accuracy:>7.1%}\")\nprint(f\"\\nOverfit check: Train R2={train_r2_check:.4f}, Test R2={r2_score(y_test, y_pred_test):.4f}\")\nprint(f\"Prediction std - Raw: {y_pred_test.std():.4f}, Calibrated: {y_pred_calibrated.std():.4f}, Actual: {y_test.std():.4f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 624
    },
    "id": "vk0ouHQRLDOC",
    "outputId": "08126a87-b3b4-42e0-eea7-ea8f04c016a0"
   },
   "outputs": [],
   "source": [
    "# Cell 6: Feature Importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, max(6, len(feature_columns) * 0.3)))\n",
    "ax.barh(importance['feature'], importance['importance'], color='steelblue')\n",
    "ax.set_xlabel('Feature Importance')\n",
    "ax.set_title('XGBoost Feature Importance (Huber Loss)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/drive/MyDrive/stock_prediction_data/feature_importance.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 10 features:\")\n",
    "for _, row in importance.tail(10).iloc[::-1].iterrows():\n",
    "    bar = '#' * int(row['importance'] * 50)\n",
    "    print(f\"  {row['feature']:30s} {row['importance']:.3f} {bar}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524
    },
    "id": "joYeIuBzLE4t",
    "outputId": "c44a120d-4228-4af4-c436-8b2b52ae27a1"
   },
   "outputs": [],
   "source": [
    "# Cell 7: Prediction Analysis â€” Compare Raw, Calibrated, and Ensemble\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# Row 1: Predicted vs Actual scatter for each method\n",
    "for col, (name, preds) in enumerate(variants.items()):\n",
    "    ax = axes[0, col]\n",
    "    ax.scatter(y_test, preds, alpha=0.5, edgecolor='black', s=40)\n",
    "    lims = [min(y_test.min(), preds.min()) - 0.05, max(y_test.max(), preds.max()) + 0.05]\n",
    "    ax.plot(lims, lims, 'r--', label='Perfect')\n",
    "    ax.set_xlabel(f'Actual {target_col}')\n",
    "    ax.set_ylabel(f'Predicted')\n",
    "    ax.set_title(f'{name}')\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    da = np.mean(np.sign(y_test) == np.sign(preds))\n",
    "    ax.text(0.05, 0.95, f'R2={r2:.3f}\\nDir={da:.1%}', transform=ax.transAxes,\n",
    "            va='top', fontsize=9, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "# Row 2, Col 0: Prediction spread comparison\n",
    "axes[1, 0].hist(y_pred_test, bins=30, alpha=0.6, label='Raw', color='blue')\n",
    "axes[1, 0].hist(y_pred_calibrated, bins=30, alpha=0.6, label='Calibrated', color='orange')\n",
    "axes[1, 0].hist(y_test, bins=30, alpha=0.4, label='Actual', color='green')\n",
    "axes[1, 0].set_xlabel('Return')\n",
    "axes[1, 0].set_title('Prediction Spread: Before vs After Calibration')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Row 2, Col 1: Cumulative returns comparison\n",
    "test_returns = dataset[test_mask]['target_return'].values\n",
    "buy_hold = np.cumprod(1 + test_returns) - 1\n",
    "for name, preds in variants.items():\n",
    "    strategy_returns = np.where(preds > 0, test_returns, 0)\n",
    "    strategy = np.cumprod(1 + strategy_returns) - 1\n",
    "    axes[1, 1].plot(range(len(strategy)), strategy, label=name, alpha=0.7)\n",
    "axes[1, 1].plot(range(len(buy_hold)), buy_hold, label='Buy & Hold', alpha=0.7, linestyle='--', color='black')\n",
    "axes[1, 1].set_xlabel('Test Sample')\n",
    "axes[1, 1].set_ylabel('Cumulative Return')\n",
    "axes[1, 1].set_title('Cumulative Returns: Model Strategies vs Buy & Hold')\n",
    "axes[1, 1].legend(fontsize=8)\n",
    "axes[1, 1].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Row 2, Col 2: Direction accuracy by method\n",
    "method_names = list(variants.keys()) + ['Classifier']\n",
    "dir_accs = [np.mean(np.sign(y_test) == np.sign(p)) for p in variants.values()] + [dir_accuracy]\n",
    "colors = ['steelblue'] * len(variants) + ['coral']\n",
    "axes[1, 2].barh(method_names, dir_accs, color=colors)\n",
    "axes[1, 2].axvline(x=0.5, color='red', linestyle='--', label='Random baseline')\n",
    "axes[1, 2].set_xlabel('Direction Accuracy')\n",
    "axes[1, 2].set_title('Direction Accuracy by Method')\n",
    "axes[1, 2].set_xlim(0.4, 0.75)\n",
    "axes[1, 2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/drive/MyDrive/stock_prediction_data/model_results.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_kc7M0NALHRQ",
    "outputId": "479f1173-de01-4a4f-c34e-50837e530d20"
   },
   "outputs": [],
   "source": [
    "# Cell 8: Save Model and Results\n",
    "\n",
    "# Pick the best-performing variant for primary metrics\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "direction_correct = np.sum(np.sign(y_test) == np.sign(y_pred_test))\n",
    "reg_direction_accuracy = direction_correct / len(y_test)\n",
    "\n",
    "# Calibrated metrics\n",
    "cal_rmse = np.sqrt(mean_squared_error(y_test, y_pred_calibrated))\n",
    "cal_r2 = r2_score(y_test, y_pred_calibrated)\n",
    "cal_dir = np.mean(np.sign(y_test) == np.sign(y_pred_calibrated))\n",
    "\n",
    "# Ensemble metrics\n",
    "ens_rmse = np.sqrt(mean_squared_error(y_test, y_pred_ensemble))\n",
    "ens_r2 = r2_score(y_test, y_pred_ensemble)\n",
    "ens_dir = np.mean(np.sign(y_test) == np.sign(y_pred_ensemble))\n",
    "\n",
    "results = {\n",
    "    'model': model,\n",
    "    'scaler': scaler,\n",
    "    'feature_columns': feature_columns,\n",
    "    'target_column': target_col,\n",
    "    'best_params': best_params,\n",
    "    'metrics': {\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2,\n",
    "        'test_mae': test_mae,\n",
    "        'direction_accuracy': float(reg_direction_accuracy),\n",
    "        'cv_rmse_mean': float(cv_rmse_mean),\n",
    "        'cv_rmse_std': float(cv_rmse_std),\n",
    "        'overfit_ratio': float(train_rmse / test_rmse),\n",
    "        # Calibrated metrics\n",
    "        'calibrated_rmse': cal_rmse,\n",
    "        'calibrated_r2': cal_r2,\n",
    "        'calibrated_direction_accuracy': float(cal_dir),\n",
    "        # Ensemble metrics\n",
    "        'ensemble_rmse': ens_rmse,\n",
    "        'ensemble_r2': ens_r2,\n",
    "        'ensemble_direction_accuracy': float(ens_dir),\n",
    "        # Classifier metrics\n",
    "        'classifier_direction_accuracy': float(dir_accuracy),\n",
    "    },\n",
    "    'split_info': {\n",
    "        'method': 'temporal',\n",
    "        'cutoff_date': str(pd.Timestamp(cutoff_date).date()),\n",
    "        'train_size': len(X_train),\n",
    "        'test_size': len(X_test),\n",
    "        'cv_folds': len(cv_splits),\n",
    "    },\n",
    "    # Save all prediction variants\n",
    "    'predictions': {\n",
    "        'y_train': y_train.tolist(),\n",
    "        'y_test': y_test.tolist(),\n",
    "        'y_pred_train': y_pred_train.tolist(),\n",
    "        'y_pred_test': y_pred_test.tolist(),\n",
    "        'y_pred_calibrated': y_pred_calibrated.tolist(),\n",
    "        'y_pred_ensemble': y_pred_ensemble.tolist(),\n",
    "        'dir_probs': dir_probs.tolist(),\n",
    "        'test_tickers': dataset[test_mask]['ticker'].tolist(),\n",
    "        'test_dates': dataset[test_mask]['date'].astype(str).tolist(),\n",
    "        'test_raw_returns': dataset[test_mask]['target_return'].tolist(),\n",
    "    },\n",
    "}\n",
    "\n",
    "with open('/content/drive/MyDrive/stock_prediction_data/model_results.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "print(\"Saved to Google Drive: model_results.pkl\")\n",
    "print(f\"\\n{'='*55}\")\n",
    "print(f\"    FINAL RESULTS SUMMARY\")\n",
    "print(f\"{'='*55}\")\n",
    "print(f\"\\nTarget: {target_col}\")\n",
    "print(f\"Samples: {len(X_train)} train / {len(X_test)} test\")\n",
    "print(f\"Features: {len(feature_columns)}\")\n",
    "print(f\"\\n--- Raw Regression (Huber Loss) ---\")\n",
    "print(f\"Train RMSE: {train_rmse:.4f}, Test RMSE: {test_rmse:.4f}\")\n",
    "print(f\"Train R2: {train_r2:.4f}, Test R2: {test_r2:.4f}\")\n",
    "print(f\"Direction: {reg_direction_accuracy:.1%}, Overfit: {train_rmse/test_rmse:.2f}\")\n",
    "print(f\"CV RMSE: {cv_rmse_mean:.4f} +/- {cv_rmse_std:.4f}\")\n",
    "print(f\"\\n--- Calibrated Regression ---\")\n",
    "print(f\"RMSE: {cal_rmse:.4f}, R2: {cal_r2:.4f}, Direction: {cal_dir:.1%}\")\n",
    "print(f\"\\n--- Ensemble ---\")\n",
    "print(f\"RMSE: {ens_rmse:.4f}, R2: {ens_r2:.4f}, Direction: {ens_dir:.1%}\")\n",
    "print(f\"\\n--- Direction Classifier ---\")\n",
    "print(f\"Direction: {dir_accuracy:.1%}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}