{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 1: Load Results and Data\nimport pandas as pd\nimport numpy as np\nimport pickle\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\n\nsns.set_style('whitegrid')\n\n# Load model results\nwith open(os.path.join('..', 'models', 'model_results.pkl'), 'rb') as f:\n    results = pickle.load(f)\n\nmodel = results['model']\nscaler = results['scaler']\nfeature_columns = results['feature_columns']\nmetrics = results['metrics']\n\n# Load dataset\ndataset = pd.read_csv(os.path.join('..', 'data', 'processed_dataset.csv'))\n\nprint(\"=== Model Results Loaded ===\")\nprint(f\"Dataset: {len(dataset)} samples\")\nprint(f\"Companies: {dataset['ticker'].nunique()}\")\nprint(f\"Features ({len(feature_columns)}): {feature_columns}\")\nprint(f\"\\nMetrics:\")\nfor k, v in metrics.items():\n    print(f\"  {k}: {v:.4f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 2: Model Performance Summary\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\nX = dataset[feature_columns].copy()\ny = dataset['target_return'].copy()\n\nX_scaled = pd.DataFrame(scaler.transform(X), columns=feature_columns)\nX_train, X_test, y_train, y_test = train_test_split(\n    X_scaled, y, test_size=0.2, random_state=42\n)\n\ny_pred_test = model.predict(X_test)\ny_pred_train = model.predict(X_train)\n\n# Direction accuracy\ndirection_correct = np.sum(np.sign(y_test.values) == np.sign(y_pred_test))\ndirection_accuracy = direction_correct / len(y_test)\n\nprint(\"=\"*55)\nprint(\"    STOCK RETURN PREDICTION - MODEL PERFORMANCE\")\nprint(\"=\"*55)\nprint(f\"\\nDataset: {len(dataset)} company-quarter samples\")\nprint(f\"Companies: {dataset['ticker'].nunique()}\")\nprint(f\"Features: {len(feature_columns)}\")\nprint(f\"Train/Test split: {len(X_train)}/{len(X_test)}\")\nprint(f\"\\n--- Regression Metrics ---\")\nprint(f\"Train RMSE: {np.sqrt(mean_squared_error(y_train, y_pred_train)):.4f}\")\nprint(f\"Test RMSE:  {np.sqrt(mean_squared_error(y_test, y_pred_test)):.4f}\")\nprint(f\"Train R2:   {r2_score(y_train, y_pred_train):.4f}\")\nprint(f\"Test R2:    {r2_score(y_test, y_pred_test):.4f}\")\nprint(f\"Test MAE:   {mean_absolute_error(y_test, y_pred_test):.4f}\")\nprint(f\"\\n--- Cross-Validation ---\")\nprint(f\"CV RMSE:    {metrics.get('cv_rmse_mean', 0):.4f} (+/- {metrics.get('cv_rmse_std', 0):.4f})\")\nprint(f\"\\n--- Direction Accuracy ---\")\nprint(f\"Correct direction: {direction_correct}/{len(y_test)} ({direction_accuracy:.1%})\")\nprint(f\"(Baseline random: 50%)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 3: Feature Importance Analysis\nimportance = pd.DataFrame({\n    'feature': feature_columns,\n    'importance': model.feature_importances_\n}).sort_values('importance', ascending=False)\n\nprint(\"Feature Importance Ranking:\")\nprint(\"-\" * 40)\nfor _, row in importance.iterrows():\n    bar = '#' * int(row['importance'] * 50)\n    print(f\"{row['feature']:25s} {row['importance']:.3f} {bar}\")\n\n# Show top 10 features in chart for readability\ntop_n = min(15, len(importance))\ntop_features = importance.head(top_n)\n\nfig, ax = plt.subplots(figsize=(10, 8))\nax.barh(top_features['feature'][::-1], top_features['importance'][::-1], color='steelblue')\nax.set_xlabel('Importance Score')\nax.set_title(f'XGBoost Feature Importance (Top {top_n} of {len(feature_columns)})')\nplt.tight_layout()\nplt.savefig(os.path.join('..', 'results', 'feature_importance_analysis.png'), dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 4: Prediction Analysis\nfig, axes = plt.subplots(2, 2, figsize=(15, 11))\n\n# 1. Predicted vs Actual\naxes[0, 0].scatter(y_test, y_pred_test, alpha=0.7, edgecolor='black', s=60)\nlims = [min(y_test.min(), y_pred_test.min()) - 0.05, max(y_test.max(), y_pred_test.max()) + 0.05]\naxes[0, 0].plot(lims, lims, 'r--', label='Perfect prediction')\naxes[0, 0].set_xlabel('Actual Return')\naxes[0, 0].set_ylabel('Predicted Return')\naxes[0, 0].set_title('Predicted vs Actual Quarterly Returns')\naxes[0, 0].legend()\n\n# 2. Residuals\nresiduals = y_test.values - y_pred_test\naxes[0, 1].hist(residuals, bins=20, edgecolor='black', alpha=0.7, color='steelblue')\naxes[0, 1].axvline(x=0, color='red', linestyle='--')\naxes[0, 1].set_xlabel('Prediction Error')\naxes[0, 1].set_ylabel('Frequency')\naxes[0, 1].set_title('Distribution of Prediction Errors')\n\n# 3. Average return by company\ncompany_returns = dataset.groupby('ticker')['target_return'].mean().sort_values()\ncolors = ['salmon' if v < 0 else 'steelblue' for v in company_returns.values]\naxes[1, 0].barh(company_returns.index, company_returns.values, color=colors)\naxes[1, 0].axvline(x=0, color='red', linestyle='--', alpha=0.5)\naxes[1, 0].set_xlabel('Average Quarterly Return')\naxes[1, 0].set_title(f'Average Return by Company ({dataset[\"ticker\"].nunique()} companies)')\naxes[1, 0].tick_params(axis='y', labelsize=7)\n\n# 4. Top feature correlations with target\ncorrelations = dataset[feature_columns + ['target_return']].corr()['target_return'].drop('target_return').sort_values()\ntop_corr = pd.concat([correlations.head(8), correlations.tail(8)]).drop_duplicates()\ncorr_colors = ['salmon' if v < 0 else 'steelblue' for v in top_corr.values]\naxes[1, 1].barh(top_corr.index, top_corr.values, color=corr_colors)\naxes[1, 1].axvline(x=0, color='red', linestyle='--', alpha=0.5)\naxes[1, 1].set_xlabel('Correlation with Target Return')\naxes[1, 1].set_title('Feature Correlations (Top/Bottom)')\n\nplt.tight_layout()\nplt.savefig(os.path.join('..', 'results', 'prediction_analysis.png'), dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 5: Correlation Heatmap\nfig, ax = plt.subplots(figsize=(16, 14))\n\ncorr_matrix = dataset[feature_columns + ['target_return']].corr()\nmask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n\nsns.heatmap(\n    corr_matrix, mask=mask, annot=True, fmt='.2f',\n    cmap='RdBu_r', center=0, square=True,\n    linewidths=0.5, ax=ax, annot_kws={'size': 6}\n)\nax.set_title('Feature Correlation Heatmap')\nax.tick_params(axis='x', labelsize=7, rotation=45)\nax.tick_params(axis='y', labelsize=7)\nplt.tight_layout()\nplt.savefig(os.path.join('..', 'results', 'correlation_heatmap.png'), dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 6: Final Summary\nprint(\"=\"*55)\nprint(\"    PROJECT SUMMARY\")\nprint(\"=\"*55)\nprint(f\"\"\"\nStock Return Prediction using XGBoost\n--------------------------------------\nObjective: Predict quarterly stock returns from\n           financial fundamentals\n\nData:\n  - {dataset['ticker'].nunique()} S&P 500 companies\n  - {len(dataset)} company-quarter samples\n  - Price data: Kaggle S&P 500 dataset (2013-2018)\n  - Financial data: Real SEC EDGAR quarterly filings\n\nFeatures ({len(feature_columns)}):\n  {', '.join(feature_columns[:13])}\n  {', '.join(feature_columns[13:])}\n\nModel: XGBoost Regressor\n  - max_depth: 4\n  - n_estimators: 200\n  - learning_rate: 0.05\n\nResults:\n  - Test RMSE: {metrics.get('test_rmse', 0):.4f}\n  - Test R2: {metrics.get('test_r2', 0):.4f}\n  - CV RMSE: {metrics.get('cv_rmse_mean', 0):.4f} (+/- {metrics.get('cv_rmse_std', 0):.4f})\n  - Direction Accuracy: {direction_accuracy:.1%}\n\nTop Features: {', '.join(importance['feature'].head(5).values)}\n\nKey Observations:\n  - Direction accuracy ({direction_accuracy:.1%}) well above 50% baseline\n  - CV RMSE ({metrics.get('cv_rmse_mean', 0):.4f}) consistent with test RMSE ({metrics.get('test_rmse', 0):.4f})\n  - Real SEC financial data provides meaningful signal\n  - {len(feature_columns)} features extracted from income, balance sheet, and cash flow\n\nPotential Improvements:\n  - Add technical indicators (RSI, MACD, moving averages)\n  - Extend price data beyond 2013-2018 for more samples\n  - Include more companies with complete SEC filings\n  - Try ensemble methods or LSTM models for time series\n\"\"\")\n\nprint(\"All results saved to results/ folder.\")\nprint(\"Project complete!\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}