{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-md-1",
   "metadata": {},
   "source": [
    "# 01 - Data Collection\n",
    "\n",
    "Runs the data collection scripts to download and prepare all raw data.\n",
    "\n",
    "**Prerequisites:**\n",
    "- SEC EDGAR bulk data downloaded to `data/raw/kaggle/sec_edgar/companyfacts/`\n",
    "- `FRED_API_KEY` set in `.env` file (free at https://fred.stlouisfed.org/)\n",
    "\n",
    "**Scripts (in order):**\n",
    "1. `download_prices.py` - S&P 500 daily prices via yfinance (~5 min)\n",
    "2. `download_spy.py` - SPY benchmark prices via yfinance\n",
    "3. `download_sectors.py` - Sector classifications from Wikipedia\n",
    "4. `download_macro.py` - Macroeconomic indicators from FRED\n",
    "5. `extract_financials.py` - Parse SEC EDGAR quarterly filings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "SCRIPTS_DIR = os.path.join('..', 'scripts')\n",
    "\n",
    "def run_script(name):\n",
    "    \"\"\"Run a script and stream its output line by line.\"\"\"\n",
    "    path = os.path.join(SCRIPTS_DIR, name)\n",
    "    print(f'\\n{\"=\" * 60}')\n",
    "    print(f'Running {name}...')\n",
    "    print(f'{\"=\" * 60}\\n', flush=True)\n",
    "    process = subprocess.Popen(\n",
    "        [sys.executable, '-u', path],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        text=True,\n",
    "    )\n",
    "    for line in process.stdout:\n",
    "        print(line, end='', flush=True)\n",
    "    process.wait()\n",
    "    if process.returncode != 0:\n",
    "        raise RuntimeError(f'{name} failed with exit code {process.returncode}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Running download_prices.py...\n",
      "============================================================\n",
      "\n",
      "Fetching S&P 500 ticker list from Wikipedia...\n",
      "Found 503 tickers.\n",
      "\n",
      "Downloading 503 tickers...\n",
      "\n",
      "  Progress: 25/503 (25 successful, 0 failed)\n",
      "  Progress: 50/503 (50 successful, 0 failed)\n",
      "  Progress: 75/503 (75 successful, 0 failed)\n",
      "  Progress: 100/503 (100 successful, 0 failed)\n",
      "  Progress: 125/503 (125 successful, 0 failed)\n",
      "  Progress: 150/503 (150 successful, 0 failed)\n",
      "  Progress: 175/503 (175 successful, 0 failed)\n",
      "  Progress: 200/503 (200 successful, 0 failed)\n",
      "  Progress: 225/503 (225 successful, 0 failed)\n",
      "  Progress: 250/503 (250 successful, 0 failed)\n",
      "  Progress: 275/503 (275 successful, 0 failed)\n",
      "  Progress: 300/503 (300 successful, 0 failed)\n",
      "  Progress: 325/503 (325 successful, 0 failed)\n",
      "  Progress: 350/503 (350 successful, 0 failed)\n",
      "  Progress: 375/503 (375 successful, 0 failed)\n",
      "  Progress: 400/503 (399 successful, 1 failed)\n",
      "  Progress: 425/503 (424 successful, 1 failed)\n",
      "  Progress: 450/503 (449 successful, 1 failed)\n",
      "  Progress: 475/503 (474 successful, 1 failed)\n",
      "  Progress: 500/503 (499 successful, 1 failed)\n",
      "\n",
      "First pass: 502 successful, 1 failed\n",
      "\n",
      "Retrying 1 failed tickers with longer delay...\n",
      "Recovered: 0\n",
      "Still failed (1): ['Q']\n",
      "\n",
      "=== Final: 502 tickers ===\n",
      "\n",
      "Saved price_data.pkl: 502 tickers\n",
      "File size: 130.3 MB\n",
      "\n",
      "Sample (MMM):\n",
      "  Date range: 2005-01-03 00:00:00 to 2026-02-24 00:00:00\n",
      "  Columns: ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
      "  Rows: 5319\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Download S&P 500 stock prices (~5 min)\n",
    "run_script('download_prices.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Running download_spy.py...\n",
      "============================================================\n",
      "\n",
      "Downloading SPY benchmark data...\n",
      "Downloaded 5319 days of SPY data\n",
      "Date range: 2005-01-03 to 2026-02-24\n",
      "Saved to c:\\Users\\chris\\stock-prediction-ml\\scripts\\..\\data\\spy_prices.pkl\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Download SPY benchmark prices\n",
    "run_script('download_spy.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Running download_sectors.py...\n",
      "============================================================\n",
      "\n",
      "Fetching S&P 500 sector data from Wikipedia...\n",
      "Total companies: 503\n",
      "Unique sectors: 11\n",
      "\n",
      "Price data tickers: 502\n",
      "Matched with sector data: 502\n",
      "\n",
      "Saved sector_data.pkl: 505 entries\n",
      "File size: 22.1 KB\n",
      "\n",
      "Sector Distribution:\n",
      "  Industrials: 79\n",
      "  Financials: 76\n",
      "  Information Technology: 71\n",
      "  Health Care: 60\n",
      "  Consumer Discretionary: 48\n",
      "  Consumer Staples: 36\n",
      "  Utilities: 31\n",
      "  Real Estate: 31\n",
      "  Materials: 26\n",
      "  Communication Services: 23\n",
      "  Energy: 22\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Download sector classifications\n",
    "run_script('download_sectors.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Running download_macro.py...\n",
      "============================================================\n",
      "\n",
      "FRED API connected successfully.\n",
      "Download range: 2005-01-01 to present\n",
      "\n",
      "Indicators to download:\n",
      "  GS10: 10-Year Treasury Constant Maturity Rate (daily)\n",
      "  VIXCLS: CBOE Volatility Index (daily)\n",
      "  UNRATE: Unemployment Rate (monthly)\n",
      "  GDP: Gross Domestic Product (quarterly)\n",
      "  CPIAUCSL: Consumer Price Index (monthly)\n",
      "\n",
      "=== Downloading ===\n",
      "  GS10: 253 observations (2005-01-01 to 2026-01-01)\n",
      "  VIXCLS: 5347 observations (2005-01-03 to 2026-02-23)\n",
      "  UNRATE: 252 observations (2005-01-01 to 2026-01-01)\n",
      "  GDP: 84 observations (2005-01-01 to 2025-10-01)\n",
      "  CPIAUCSL: 252 observations (2005-01-01 to 2026-01-01)\n",
      "\n",
      "Downloaded 5/5 indicators\n",
      "\n",
      "=== Resampling to daily frequency ===\n",
      "  GS10: 253 raw -> 7671 daily observations\n",
      "  VIXCLS: 5347 raw -> 7722 daily observations\n",
      "  UNRATE: 252 raw -> 7671 daily observations\n",
      "  GDP: 84 raw -> 7579 daily observations\n",
      "  CPIAUCSL: 252 raw -> 7671 daily observations\n",
      "\n",
      "Saved macro_data.pkl\n",
      "File size: 900.6 KB\n",
      "Indicators: ['GS10', 'VIXCLS', 'UNRATE', 'GDP', 'CPIAUCSL']\n",
      "\n",
      "Sample values at 2020-03-15 (COVID):\n",
      "  GS10: 0.87\n",
      "  VIXCLS: 57.83\n",
      "  UNRATE: 4.40\n",
      "  GDP: 21751.24\n",
      "  CPIAUCSL: 258.08\n",
      "\n",
      "Verification passed! Done.\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Download macroeconomic data\n",
    "run_script('download_macro.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ytdbclyptak",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Running download_ff_factors.py...\n",
      "============================================================\n",
      "\n",
      "=== Fama-French Factor Download ===\n",
      "Start date: 2005-01-01\n",
      "\n",
      "Downloading FF5 factors (SMB, HML, RMW, CMA)...\n",
      "  Fetching F-F_Research_Data_5_Factors_2x3_CSV.zip ...\n",
      "  Parsed 750 monthly rows | columns: ['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA', 'RF']\n",
      "  Date range: 1963-07-31 to 2025-12-31\n",
      "\n",
      "Downloading Momentum factor (MOM)...\n",
      "  Fetching F-F_Momentum_Factor_CSV.zip ...\n",
      "  Added MOM (source column: Mom)\n",
      "\n",
      "Filtered to 2005-01-01: 252 monthly observations\n",
      "\n",
      "=== Resampling to daily frequency ===\n",
      "  SMB: 252 monthly -> 7640 daily observations\n",
      "  HML: 252 monthly -> 7640 daily observations\n",
      "  RMW: 252 monthly -> 7640 daily observations\n",
      "  CMA: 252 monthly -> 7640 daily observations\n",
      "  MOM: 252 monthly -> 7640 daily observations\n",
      "\n",
      "Saved ff_factors.pkl (898.0 KB)\n",
      "Factors saved: ['SMB', 'HML', 'RMW', 'CMA', 'MOM']\n",
      "\n",
      "Sample values at 2020-03-31 (COVID quarter end):\n",
      "  SMB: -0.0818\n",
      "  HML: -0.1383\n",
      "  RMW: -0.0161\n",
      "  CMA: +0.0119\n",
      "  MOM: +0.0821\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Step 4b: Download Fama-French portfolio factors (SMB, HML, RMW, CMA, MOM)\n",
    "# Free data from Kenneth French's data library — no API key needed\n",
    "run_script('download_ff_factors.py')"
   ]
  },
  {
   "cell_type": "code",
   "id": "zblj0aqbs7j",
   "source": "# Step 4c: Form 4 insider trading (disabled — too slow for practical use)\n# Downloading each Form 4 XML individually takes ~170+ hours for 443 companies.\n# Notebook 02 handles the missing file gracefully (insider_net_dir defaults to 0.0).\n# run_script('download_insider_trading.py')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Running extract_financials.py...\n",
      "============================================================\n",
      "\n",
      "SEC data dir: c:\\Users\\chris\\stock-prediction-ml\\data\\raw\\kaggle\\sec_edgar\\companyfacts\n",
      "SEC files found: 18848\n",
      "Price data: 502 companies\n",
      "\n",
      "Fetching S&P 500 CIK mapping from Wikipedia...\n",
      "S&P 500 tickers with SEC EDGAR + price data: 450\n",
      "\n",
      "=== Parsing 450 companies ===\n",
      "(quality thresholds: income_metrics >= 4, quarters >= 8)\n",
      "\n",
      "  [50/450] BRK-B: 6 income + 6 balance, 52 quarters\n",
      "  [100/450] CVS: 9 income + 11 balance, 53 quarters\n",
      "  [150/450] FCX: 9 income + 9 balance, 54 quarters\n",
      "  [200/450] IBM: 10 income + 10 balance, 53 quarters\n",
      "  [250/450] LYB: 10 income + 11 balance, 45 quarters\n",
      "  [300/450] NVR: 6 income + 6 balance, 50 quarters\n",
      "  [350/450] RMD: 11 income + 11 balance, 50 quarters\n",
      "  [400/450] TSN: 9 income + 8 balance, 50 quarters\n",
      "  [450/450] ZTS: 8 income + 11 balance, 42 quarters\n",
      "\n",
      "--- Results ---\n",
      "Loaded: 443 companies\n",
      "Skipped: 7 (insufficient data)\n",
      "Errors: 0\n",
      "\n",
      "Skipped: ['AZO (9 income, 1 quarters)', 'BLK (6 income, 7 quarters)', 'COST (9 income, 2 quarters)', 'DPZ (9 income, 1 quarters)', 'KR (0 income, 0 quarters)', 'PEP (0 income, 0 quarters)', 'PSKY (7 income, 3 quarters)']\n",
      "\n",
      "=== Data Quality Report ===\n",
      "\n",
      "Metric Coverage (% of companies):\n",
      "  Cost of Revenue                311/443 (70%)\n",
      "  EPS Basic                      433/443 (98%)\n",
      "  EPS Diluted                    433/443 (98%)\n",
      "  Gross Profit                   185/443 (42%)\n",
      "  Income Tax                     437/443 (99%)\n",
      "  Interest Expense               378/443 (85%)\n",
      "  Net Income                     436/443 (98%)\n",
      "  Operating Income               374/443 (84%)\n",
      "  R&D Expense                    137/443 (31%)\n",
      "  SGA Expense                    302/443 (68%)\n",
      "  Total Revenue                  439/443 (99%)\n",
      "  Capital Expenditures           407/443 (92%)\n",
      "  Cash                           431/443 (97%)\n",
      "  Current Assets                 375/443 (85%)\n",
      "  Current Liabilities            375/443 (85%)\n",
      "  Long Term Debt                 375/443 (85%)\n",
      "  Operating Cash Flow            443/443 (100%)\n",
      "  Shares Outstanding             305/443 (69%)\n",
      "  Short Term Debt                246/443 (56%)\n",
      "  Stockholders Equity            436/443 (98%)\n",
      "  Total Assets                   443/443 (100%)\n",
      "  Total Liabilities              443/443 (100%)\n",
      "\n",
      "Quarters per Company:\n",
      "  Min: 8, Max: 69, Mean: 46.9, Median: 50\n",
      "\n",
      "=== Saved ===\n",
      "  financial_data.pkl - 443 companies\n",
      "  tickers.pkl - 443 tickers\n",
      "\n",
      "Verification (A):\n",
      "  Income: (10, 50) (metrics x quarters)\n",
      "  Balance: (11, 68)\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Extract financial data from SEC EDGAR\n",
    "run_script('extract_financials.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": "# Verify all output files exist\nimport pickle\n\nDATA_DIR = os.path.join('..', 'data')\n\nexpected_files = {\n    'price_data.pkl': 'Stock prices',\n    'spy_prices.pkl': 'SPY benchmark',\n    'sector_data.pkl': 'Sector classifications',\n    'macro_data.pkl': 'Macro indicators',\n    'ff_factors.pkl': 'Fama-French factors',\n    'financial_data.pkl': 'Financial statements',\n    'tickers.pkl': 'Ticker list',\n}\n\nprint('=== Data Collection Summary ===')\nall_ok = True\nfor filename, desc in expected_files.items():\n    path = os.path.join(DATA_DIR, filename)\n    if os.path.exists(path):\n        size = os.path.getsize(path) / 1024 / 1024\n        with open(path, 'rb') as f:\n            data = pickle.load(f)\n        if isinstance(data, dict):\n            count = len(data)\n        elif isinstance(data, list):\n            count = len(data)\n        else:\n            count = len(data)\n        print(f'  {filename:<25s} {desc:<25s} {count:>5} items  ({size:.1f} MB)')\n    else:\n        print(f'  {filename:<25s} MISSING')\n        all_ok = False\n\nif all_ok:\n    print('\\nAll data files present. Ready for notebook 02.')\nelse:\n    print('\\nSome files missing - check script output above.')"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}